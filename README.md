# CPU & GPU DFT/FFT Benchmarking and Performance Analysis ![Python](https://img.shields.io/badge/python-3.8%2B-blue) ![C++](https://img.shields.io/badge/C%2B%2B-17-brightgreen) ![MIT License](https://img.shields.io/badge/license-MIT-lightgrey)

A comprehensive repository showcasing **different CPU and GPU implementations of Discrete Fourier Transform (DFT) and Fast Fourier Transform (FFT)**.
It is designed for **performance analysis and algorithm optimization** using profiling tools such as **Intel VTune** for CPU and **NVIDIA Nsight** for GPU. Compare scalability, execution time, and speedup of multiple implementations using single runs or Hydra-powered multiruns.

This repository was developed as a **Computer Architecture exam project at the University of Pisa**.

---

## Requirements

### Hardware

* **CPU**: Multi-core processor with OpenMP support  
  - Recommended: 4+ cores (Intel recommended for performance analysis with Intel VTune)  
* **GPU**: NVIDIA GPU with CUDA support (required for compiling GPU implementations and for testing)
  - Minimum: Compute Capability 6.0 (Pascal, required by CUDA Toolkit 12)  
  - Tested on **GeForce RTX 3050 Mobile**, Compute Capability 8.6, 4 GB VRAM  
  - Higher VRAM may be required for GPU execution on large files  
* **RAM**: 4 GB minimum  
  - Tested with 16 GB RAM, useful for large datasets  
* **Disk space**:  
  - Project itself: < 1 GB  
  - Generated data and results: up to several GB depending on input size  
    - Example: a file with 2^27 complex numbers (~134M) ≈ 5 GB  
  - Recommended free space: ≥ 10 GB if running large-scale experiments  

### Software

* **Python 3.8+** (recommended 3.11)  
* **C++ compiler** with OpenMP support (e.g., MSVC, GCC via MSYS2, or Clang)  
* **CUDA Toolkit 12+**  
* **NVIDIA GPU** for CUDA executables  
* **Windows PowerShell** for compilation scripts  
* **Intel VTune** for CPU profiling  
* **NVIDIA Nsight** for GPU profiling

### Python Libraries

```bash
pip install pandas matplotlib hydra-core omegaconf
```

* `pandas`: read and process CSV results
* `matplotlib`: plot execution time and speedup
* `hydra-core`: configuration management for single/multiruns
* `omegaconf`: used by Hydra to handle configuration dictionaries

---

## Quick Start (3 Steps)

### ⚠️ Important Note

All scripts **must be executed from the root folder of the project**.
Even if it might technically work from other directories, the project has been tested only when run from the root folder.

### 1️⃣ Clone & Setup

```bash
git clone <repo_url>
cd <project_root>
pip install pandas matplotlib hydra-core omegaconf
```

### 2️⃣ Generate Data

```bash
python data/scripts/generate_complex.py 1024
python data/scripts/generate_pow2_complex.py 10
```

* `generate_complex.py`: generate N complex numbers
* `generate_pow2_complex.py`: generate 2^N complex numbers (required for FFT)

### 3️⃣ Compile & Run

**CPU Compilation:**

```powershell
scripts\cpu_version\OMP_compile.ps1
```

**GPU Compilation:**

```powershell
scripts\gpu_version\CUDA_compile.ps1
```

**Single Run:**

```bash
# CPU
python scripts/run_cpp.py <relative_path_to_executable_cpu> <num_threads> <input_file> <num_runs>

# GPU
python scripts/run_cpp.py <relative_path_to_executable_gpu> <threads_per_block> <input_file> <num_runs> --cuda
```

**Generic usage examples:**

```bash
# CPU
python scripts/run_cpp.py scripts/cpu_version/build/OMP_DFT_optimized.exe 8 data/numbers_1024.txt 1

# GPU
python scripts/run_cpp.py scripts/gpu_version/build/CUDA_fft.exe 256 data/numbers_1048576.txt 1 --cuda
```

* `<relative_path_to_executable_cpu>` and `<relative_path_to_executable_gpu>`: relative path from the **project root** to the executable you want to run.

**Hydra-based Multirun:**

```bash
python scripts/run_cpp_hydra.py -m
```

> Always execute these commands **from the project root** to ensure correct file paths and log saving.

---

## Repository Structure

```
+---config
|       config.yaml                        # Parameters for Hydra-based execution and multirun
+---data
|   |   numbers_*.txt                      # Input datasets of complex numbers
|   \---scripts
|           generate_complex.py            # Generate N complex numbers
|           generate_pow2_complex.py       # Generate 2^N complex numbers
+---logs                                   # Execution logs
|   +---multirun
|   \---outputs
+---results
|   +---plots                              # Plots generated by the notebook
|   +---scripts
|           plot_results.ipynb         # Reads CSV results and plots performance
|   \---tables
|           CPU_details.csv
|           CPU_mean.csv
|           GPU_details.csv
\---scripts
    |   run_cpp.py                         # Run a single executable
    |   run_cpp_hydra.py                   # Run single/multirun using Hydra config
    +---cpu_version
    |   |   OMP_compile.ps1                # Compile all CPU source files
    |   +---build
    |   \---source
    \---gpu_version
        |   CUDA_compile.ps1               # Compile all CUDA source files
        |   CUDA_profile.ps1               # Generate profiling reports
        +---build
        +---profiling                      # Nsight Compute .ncu-rep reports
        \---source
```

---

## CPU Implementation

* Multi-threaded DFT/FFT using OpenMP.
* Source: `scripts/cpu_version/source/*.cpp`
* Libraries:

```cpp
#include <iostream>
#include <fstream>
#include <vector>
#include <complex>
#include <cmath>
#include <algorithm>
#include <chrono>
#include <iomanip>
#include <omp.h>
```

* Compile: `OMP_compile.ps1`
* Execute:

```bash
<executable_cpu> <num_threads> <input_file> [num_runs]
```

---

## GPU Implementation

* CUDA-based DFT/FFT and cuFFT.
* Source: `scripts/gpu_version/source/*.cu`
* Libraries:

```cpp
#include <iostream>
#include <fstream>
#include <vector>
#include <complex>
#include <cmath>
#include <iomanip>
#include <cuda_runtime.h>
#include <cuComplex.h>
#include <chrono>
#include <cufft.h>
```

* Compile: `CUDA_compile.ps1`
* Profiling: `CUDA_profile.ps1` → `.ncu-rep` reports in `profiling/`
  ⚠️ Must be executed from **PowerShell with Administrator privileges**  
* Execute:

```bash
<executable_gpu> <threads_per_block> <input_file> [num_runs]
```

---

## Analyze Results

* Use `results/scripts/plot_results.ipynb` to generate plots of execution times and speedups.

* CSV results:

  * CPU: `Num Execution,Num Threads,Input File,Run,Execution Time (ms),Executable`
  * GPU: `Num Execution,Threads per Block,Input File,Run,Execution Time (ms),Executable`

* Kernel: Anaconda3 + Python 3.11

---

## Contributors

This project was developed in collaboration between:

- **[Noemi Cherchi](https://github.com/noemichem)** – repository owner  
- **[Flavio Messina](https://github.com/f-messina)**  
- **[Alessandro Ciarniello](https://github.com/a-ciarniello)**

---

## License

This project is licensed under the **MIT License** – see [LICENSE](LICENSE) for details.
